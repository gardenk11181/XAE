{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "sys.path.append('/'.join(os.getcwd().split('/')))\n",
    "import dataset\n",
    "from util import init_params\n",
    "from sampler import gaus\n",
    "from dataset import eYaleB, MNIST\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dd = eYaleB('/home/reddragon/data/face_detected_resized', label = False)\n",
    "dd = MNIST('/home/reddragon/data/MNIST', train = False, label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "rand_sampler = torch.utils.data.RandomSampler(dd, replacement = True, num_samples = batch_size * 100)\n",
    "train_data_loader = torch.utils.data.DataLoader(dd, batch_size, num_workers = 5, sampler = rand_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2547485828399658"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "for x in train_data_loader:\n",
    "    pass\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dd, 2, num_workers = 5, shuffle = True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay = 1.0\n",
    "lamb = lambda e: decay * 1.0 * (0.5 ** (e >= 2)) * (0.2 ** (e >= 4)) * (0.1 ** (e >= 6))\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(1,10),\n",
    "    nn.Linear(10,1)\n",
    ")\n",
    "optimizer = optim.Adam(list(net.parameters()))\n",
    "scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "0.001\n",
      "0.0005\n",
      "0.00025\n",
      "2.5e-05\n",
      "2.5e-06\n",
      "2.5000000000000005e-08\n",
      "2.500000000000001e-10\n",
      "2.500000000000002e-12\n",
      "2.5000000000000023e-14\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 64\n",
    "embed_data = nn.Sequential(\n",
    "    nn.Conv2d(1, d, kernel_size = 5, stride = 2, padding = 2, bias = False),\n",
    "    nn.BatchNorm2d(d),\n",
    "    nn.ReLU(True),\n",
    ")\n",
    "embed_condition = nn.Sequential(\n",
    "    nn.Linear(40, 64*64),\n",
    "    nn.Unflatten(1, (1,64,64)),\n",
    ")\n",
    "enc = nn.Sequential(\n",
    "    nn.Conv2d(d+1, 2*d, kernel_size = 5, stride = 2, padding = 2, bias = False),\n",
    "    nn.BatchNorm2d(2*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(2*d, 4*d, kernel_size = 5, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(4*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(4*d, 8*d, kernel_size = 3, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(8*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(8*d, 16*d, kernel_size = 3, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(16*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16*16*d, 16)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(torch.cat((embed_data(x), embed_condition(y)), dim = 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reddragon/.conda/envs/torch/lib/python3.6/site-packages/torch/nn/modules/conv.py:443: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  /opt/conda/conda-bld/pytorch_1628579264685/work/aten/src/ATen/native/Convolution.cpp:647.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 28, 28])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 128\n",
    "enc = nn.Sequential(\n",
    "    nn.Conv2d(1, d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(d, 2*d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(2*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(2*d, 4*d, kernel_size = 4, stride = 2, padding = 2, bias = False),\n",
    "    nn.BatchNorm2d(4*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(4*d, 8*d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(8*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(4*8*d, 8),\n",
    "    )\n",
    "\n",
    "dec = nn.Sequential(\n",
    "    nn.Linear(8, 49*8*d),\n",
    "    nn.Unflatten(1, (8*d, 7, 7)),\n",
    "\n",
    "    nn.ConvTranspose2d(8*d, 4*d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(4*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose2d(4*d, 2*d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(2*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    # reconstruction\n",
    "    nn.Conv2d(2*d, 1, kernel_size = 4, padding = 'same'),\n",
    "    nn.Tanh(),\n",
    "    )\n",
    "dec(enc(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.3889, -0.3889],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1111,  0.1111],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6111, -0.2222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1944,  0.7222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6111,  0.7222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6667,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1389,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4722,  0.2222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0556, -0.2222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.1389,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6111, -0.2222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1944,  0.7222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.3333,  0.2222],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.6111,  0.4444],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.6111,  0.1667],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6111,  0.1667]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset' from '/home/reddragon/projects/XAE/XAE/dataset.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6208],\n",
      "        [-1.3205]])\n"
     ]
    }
   ],
   "source": [
    "_base_model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []\n",
    "aa.append(nn.Conv2d(3, 3, kernel_size = 3))\n",
    "aa.append(nn.Conv2d(3, 3, kernel_size = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class test():\n",
    "    def __init__(self):\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.c1 = nn.Linear(1, 5)\n",
    "        self.c2 = nn.Linear(5, 1)\n",
    "        self.c3 = nn.Linear(5, 1)\n",
    "        self.all_nets = [self.c1, self.c2]\n",
    "        self.all_nets2 = [self.c3]\n",
    "\n",
    "    def initialize(self):\n",
    "        for net in self.all_nets:\n",
    "            init_params(net)\n",
    "\n",
    "    def cmse(self, x,y):\n",
    "        return -self.mse(x,y)\n",
    "\n",
    "    def all_params(self):\n",
    "        # return list(self.c1.parameters()) + list(self.c2.parameters())\n",
    "        return sum([list(net.parameters()) for net in self.all_nets], []) + sum([list(net.parameters()) for net in self.all_nets2], [])\n",
    "        # return sum([list(net.parameters()) for net in self.all_nets],[])\n",
    "\n",
    "cc = test()\n",
    "cc.cmse(torch.zeros(3,1), torch.ones(3,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test2, self).__init__()\n",
    "        self.c1 = nn.Linear(1, 5)\n",
    "        self.c2 = nn.Linear(5, 1)\n",
    "        self.c3 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.c2(self.c1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_loss(self, x, y, n):\n",
    "        logPz = self.discriminate(x)\n",
    "        logQz = self.discriminate(y)\n",
    "        return self.bceloss(logPz, torch.zeros_like(logPz)) + self.bceloss(logQz, torch.ones_like(logQz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = nn.Sequential(\n",
    "        nn.Linear(8, 64),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(True),\n",
    "\n",
    "        nn.Linear(16, 1),\n",
    "        )\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5398e-05],\n",
       "        [4.5398e-05],\n",
       "        [4.5398e-05],\n",
       "        [4.5398e-05],\n",
       "        [4.5398e-05]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.sigmoid(torch.ones(5, 1) * -10.0) + 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.0000],\n",
       "        [-10.0000],\n",
       "        [-10.0000],\n",
       "        [-10.0000],\n",
       "        [-10.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPS = 1e-15\n",
    "torch.log(nn.functional.sigmoid(torch.ones(5, 1) * -10.0) + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.0000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.ones(5, 1) * -10.0, torch.ones(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4741)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.ones(10,1)*0.5, torch.ones(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3133],\n",
       "        [0.3133],\n",
       "        [0.3133],\n",
       "        [0.3133],\n",
       "        [0.3133]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(torch.sigmoid(torch.ones(5, 1)) + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3133],\n",
       "        [1.3133],\n",
       "        [1.3133],\n",
       "        [1.3133],\n",
       "        [1.3133]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(1 - torch.sigmoid(torch.ones(5, 1)) + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8216, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = gaus(8, 8)\n",
    "y = disc(x)\n",
    "criterion(y, torch.zeros_like(y)) +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros_like(y) * -10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3863)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(y, torch.ones_like(y)) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3133)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.ones_like(y), torch.ones_like(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3133)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.ones_like(y), torch.zeros_like(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3133)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.ones_like(y), -torch.ones_like(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3133)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.ones_like(y), torch.ones_like(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3133)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(-torch.ones_like(y), torch.ones_like(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedLayer(nn.Module):\n",
    "    def __init__(self, p, q, i, prob = True):\n",
    "        super(MixedLayer, self).__init__()\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.i = i\n",
    "        self.mu = nn.Linear(p, q)\n",
    "        if prob:\n",
    "            self.logvar = nn.Linear(p, q)\n",
    "    def forward(self, x):\n",
    "        if prob:\n",
    "            torch.cat((self.lin(x[:, 0:self.p]), x[:, self.p:(self.p+self.i)]), axis = 1)\n",
    "        return torch.cat((self.lin(x[:, 0:self.p]), x[:, self.p:(self.p+self.i)]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = MixedLayer(4, 2, 2)\n",
    "init_params(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0065,  0.0040, -0.0011,  0.0109],\n",
      "        [ 0.0133,  0.0128,  0.0037, -0.0115]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1375, 0.1806], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in bb.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1543, 0.6921, 0.2273, 0.5626, 0.4695, 0.7117],\n",
       "        [0.2035, 0.9041, 0.0019, 0.0801, 0.5793, 0.5400]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2,6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1471, 0.1858, 0.4695, 0.7117],\n",
       "        [0.1433, 0.1939, 0.5793, 0.5400]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('c1.weight',\n",
       "              tensor([[ 0.5197],\n",
       "                      [ 0.2178],\n",
       "                      [ 0.6304],\n",
       "                      [-0.0735],\n",
       "                      [-0.6911]])),\n",
       "             ('c1.bias',\n",
       "              tensor([ 0.0903, -0.9596,  0.9422,  0.2009, -0.7207])),\n",
       "             ('c2.weight',\n",
       "              tensor([[ 0.1804,  0.0569,  0.3982,  0.1495, -0.0191]])),\n",
       "             ('c2.bias', tensor([0.1114])),\n",
       "             ('c3.weight',\n",
       "              tensor([[-0.0667, -0.3785,  0.1985,  0.2912,  0.1087]])),\n",
       "             ('c3.bias', tensor([-0.1786]))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = test2()\n",
    "tt.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1718, 0.1337, 0.1460, 0.1453, 0.0997],\n",
       "        [0.1718, 0.1337, 0.1460, 0.1453, 0.0997]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.initialize()\n",
    "cc.c1(torch.ones(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1718, 0.1337, 0.1460, 0.1453, 0.0997],\n",
       "        [0.1718, 0.1337, 0.1460, 0.1453, 0.0997]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.all_nets[0](torch.ones(2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.1250, -0.0502,  0.1356],\n",
       "           [ 0.0441, -0.0939,  0.1377],\n",
       "           [-0.0796,  0.1658, -0.1213]],\n",
       " \n",
       "          [[-0.1224,  0.1321, -0.0536],\n",
       "           [-0.1582,  0.0461, -0.1887],\n",
       "           [-0.0433, -0.1256,  0.0193]],\n",
       " \n",
       "          [[ 0.0326,  0.1915, -0.1872],\n",
       "           [-0.1299,  0.1529, -0.1083],\n",
       "           [-0.1577,  0.1423, -0.0041]]],\n",
       " \n",
       " \n",
       "         [[[-0.0793, -0.0233, -0.0613],\n",
       "           [ 0.1125, -0.1068,  0.1370],\n",
       "           [-0.1799, -0.1326,  0.0041]],\n",
       " \n",
       "          [[-0.0294, -0.1305,  0.1242],\n",
       "           [-0.0774,  0.1900, -0.0029],\n",
       "           [ 0.0664,  0.1848,  0.0539]],\n",
       " \n",
       "          [[ 0.1042, -0.1635,  0.1009],\n",
       "           [ 0.0298, -0.0833,  0.1036],\n",
       "           [ 0.0288,  0.0512, -0.1495]]],\n",
       " \n",
       " \n",
       "         [[[-0.0080, -0.1605, -0.1426],\n",
       "           [-0.1732,  0.0027, -0.1489],\n",
       "           [ 0.1298, -0.0741,  0.1302]],\n",
       " \n",
       "          [[-0.0244,  0.1439, -0.1660],\n",
       "           [ 0.0415,  0.0733,  0.0670],\n",
       "           [ 0.1632, -0.0364,  0.1216]],\n",
       " \n",
       "          [[ 0.1031,  0.0161,  0.0636],\n",
       "           [-0.1640, -0.0588, -0.0483],\n",
       "           [-0.0641, -0.0122,  0.0722]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0206, -0.0613,  0.1320], requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(aa[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.1250, -0.0502,  0.1356],\n",
       "           [ 0.0441, -0.0939,  0.1377],\n",
       "           [-0.0796,  0.1658, -0.1213]],\n",
       " \n",
       "          [[-0.1224,  0.1321, -0.0536],\n",
       "           [-0.1582,  0.0461, -0.1887],\n",
       "           [-0.0433, -0.1256,  0.0193]],\n",
       " \n",
       "          [[ 0.0326,  0.1915, -0.1872],\n",
       "           [-0.1299,  0.1529, -0.1083],\n",
       "           [-0.1577,  0.1423, -0.0041]]],\n",
       " \n",
       " \n",
       "         [[[-0.0793, -0.0233, -0.0613],\n",
       "           [ 0.1125, -0.1068,  0.1370],\n",
       "           [-0.1799, -0.1326,  0.0041]],\n",
       " \n",
       "          [[-0.0294, -0.1305,  0.1242],\n",
       "           [-0.0774,  0.1900, -0.0029],\n",
       "           [ 0.0664,  0.1848,  0.0539]],\n",
       " \n",
       "          [[ 0.1042, -0.1635,  0.1009],\n",
       "           [ 0.0298, -0.0833,  0.1036],\n",
       "           [ 0.0288,  0.0512, -0.1495]]],\n",
       " \n",
       " \n",
       "         [[[-0.0080, -0.1605, -0.1426],\n",
       "           [-0.1732,  0.0027, -0.1489],\n",
       "           [ 0.1298, -0.0741,  0.1302]],\n",
       " \n",
       "          [[-0.0244,  0.1439, -0.1660],\n",
       "           [ 0.0415,  0.0733,  0.0670],\n",
       "           [ 0.1632, -0.0364,  0.1216]],\n",
       " \n",
       "          [[ 0.1031,  0.0161,  0.0636],\n",
       "           [-0.1640, -0.0588, -0.0483],\n",
       "           [-0.0641, -0.0122,  0.0722]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0206, -0.0613,  0.1320], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.1737, -0.1494, -0.1306],\n",
       "           [-0.0512,  0.1001, -0.1609],\n",
       "           [-0.1725, -0.0437, -0.0138]],\n",
       " \n",
       "          [[-0.0656,  0.0660,  0.0162],\n",
       "           [-0.0025, -0.1707, -0.1050],\n",
       "           [-0.1826, -0.0128,  0.0607]],\n",
       " \n",
       "          [[ 0.1055,  0.1399, -0.1632],\n",
       "           [ 0.1650, -0.0588,  0.0622],\n",
       "           [ 0.0238, -0.0712,  0.1719]]],\n",
       " \n",
       " \n",
       "         [[[-0.0282, -0.1507, -0.1513],\n",
       "           [-0.1859,  0.0291,  0.1685],\n",
       "           [ 0.0076, -0.0459,  0.1806]],\n",
       " \n",
       "          [[ 0.0858, -0.0167, -0.0423],\n",
       "           [ 0.0789, -0.0615, -0.0497],\n",
       "           [-0.1747,  0.1410, -0.0079]],\n",
       " \n",
       "          [[-0.0745,  0.1570,  0.0012],\n",
       "           [-0.0967, -0.0885, -0.0286],\n",
       "           [ 0.0068,  0.0830, -0.0312]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1653, -0.0999, -0.0169],\n",
       "           [-0.1681,  0.1793,  0.1290],\n",
       "           [-0.0015,  0.0850,  0.1013]],\n",
       " \n",
       "          [[ 0.0787, -0.1586,  0.0058],\n",
       "           [-0.1908,  0.1238,  0.0915],\n",
       "           [ 0.1232,  0.0146,  0.0580]],\n",
       " \n",
       "          [[-0.1801,  0.0827,  0.0911],\n",
       "           [ 0.1193, -0.0445, -0.0694],\n",
       "           [-0.1261,  0.1331,  0.0480]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0658, -0.0209,  0.0224], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(aa[0].parameters()) + list(aa[1].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931471805599453"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(0.5)*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.1250, -0.0502,  0.1356],\n",
       "           [ 0.0441, -0.0939,  0.1377],\n",
       "           [-0.0796,  0.1658, -0.1213]],\n",
       " \n",
       "          [[-0.1224,  0.1321, -0.0536],\n",
       "           [-0.1582,  0.0461, -0.1887],\n",
       "           [-0.0433, -0.1256,  0.0193]],\n",
       " \n",
       "          [[ 0.0326,  0.1915, -0.1872],\n",
       "           [-0.1299,  0.1529, -0.1083],\n",
       "           [-0.1577,  0.1423, -0.0041]]],\n",
       " \n",
       " \n",
       "         [[[-0.0793, -0.0233, -0.0613],\n",
       "           [ 0.1125, -0.1068,  0.1370],\n",
       "           [-0.1799, -0.1326,  0.0041]],\n",
       " \n",
       "          [[-0.0294, -0.1305,  0.1242],\n",
       "           [-0.0774,  0.1900, -0.0029],\n",
       "           [ 0.0664,  0.1848,  0.0539]],\n",
       " \n",
       "          [[ 0.1042, -0.1635,  0.1009],\n",
       "           [ 0.0298, -0.0833,  0.1036],\n",
       "           [ 0.0288,  0.0512, -0.1495]]],\n",
       " \n",
       " \n",
       "         [[[-0.0080, -0.1605, -0.1426],\n",
       "           [-0.1732,  0.0027, -0.1489],\n",
       "           [ 0.1298, -0.0741,  0.1302]],\n",
       " \n",
       "          [[-0.0244,  0.1439, -0.1660],\n",
       "           [ 0.0415,  0.0733,  0.0670],\n",
       "           [ 0.1632, -0.0364,  0.1216]],\n",
       " \n",
       "          [[ 0.1031,  0.0161,  0.0636],\n",
       "           [-0.1640, -0.0588, -0.0483],\n",
       "           [-0.0641, -0.0122,  0.0722]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0206, -0.0613,  0.1320], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.1737, -0.1494, -0.1306],\n",
       "           [-0.0512,  0.1001, -0.1609],\n",
       "           [-0.1725, -0.0437, -0.0138]],\n",
       " \n",
       "          [[-0.0656,  0.0660,  0.0162],\n",
       "           [-0.0025, -0.1707, -0.1050],\n",
       "           [-0.1826, -0.0128,  0.0607]],\n",
       " \n",
       "          [[ 0.1055,  0.1399, -0.1632],\n",
       "           [ 0.1650, -0.0588,  0.0622],\n",
       "           [ 0.0238, -0.0712,  0.1719]]],\n",
       " \n",
       " \n",
       "         [[[-0.0282, -0.1507, -0.1513],\n",
       "           [-0.1859,  0.0291,  0.1685],\n",
       "           [ 0.0076, -0.0459,  0.1806]],\n",
       " \n",
       "          [[ 0.0858, -0.0167, -0.0423],\n",
       "           [ 0.0789, -0.0615, -0.0497],\n",
       "           [-0.1747,  0.1410, -0.0079]],\n",
       " \n",
       "          [[-0.0745,  0.1570,  0.0012],\n",
       "           [-0.0967, -0.0885, -0.0286],\n",
       "           [ 0.0068,  0.0830, -0.0312]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1653, -0.0999, -0.0169],\n",
       "           [-0.1681,  0.1793,  0.1290],\n",
       "           [-0.0015,  0.0850,  0.1013]],\n",
       " \n",
       "          [[ 0.0787, -0.1586,  0.0058],\n",
       "           [-0.1908,  0.1238,  0.0915],\n",
       "           [ 0.1232,  0.0146,  0.0580]],\n",
       " \n",
       "          [[-0.1801,  0.0827,  0.0911],\n",
       "           [ 0.1193, -0.0445, -0.0694],\n",
       "           [-0.1261,  0.1331,  0.0480]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0658, -0.0209,  0.0224], requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([list(net.parameters()) for net in aa], [])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d77abe1f91c93046f1735f3da40ae4cbc8fa8253ee46f96b7b2c304a8ef5c243"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
