{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, configparser, logging, argparse\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-2]))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from XAE.dataset import rmMNIST\n",
    "from XAE.util import init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "d = 64\n",
    "embed_data = nn.Sequential(\n",
    "    nn.Conv2d(1, d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(d, d, kernel_size = 4, padding = 'same', bias = False),\n",
    "    nn.BatchNorm2d(d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(d, 2*d, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "    nn.BatchNorm2d(2*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Conv2d(2*d, 2*d, kernel_size = 4, padding = 'same', bias = False),\n",
    "    nn.BatchNorm2d(2*d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Flatten(),\n",
    ").to(device)\n",
    "\n",
    "embed_condition = nn.Sequential(\n",
    "    nn.Linear(49*2*d, d),\n",
    "    nn.BatchNorm1d(d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Linear(d, 10),\n",
    "\n",
    "#     nn.Softmax(dim = 1)\n",
    ").to(device)\n",
    "\n",
    "init_params(embed_data)\n",
    "init_params(embed_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(iter(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = rmMNIST('/home/reddragon/data/MNIST', train = True, label = True, aux = [[i for i in range(10)], []], portion = 0.5)\n",
    "train_generator = torch.utils.data.DataLoader(train_data, 100, num_workers = 5, shuffle = True, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.828\n",
      "[2] loss: 0.070\n",
      "[3] loss: 0.034\n",
      "[4] loss: 0.022\n",
      "[5] loss: 0.015\n",
      "[6] loss: 0.011\n",
      "[7] loss: 0.006\n",
      "[8] loss: 0.007\n",
      "[9] loss: 0.004\n",
      "[10] loss: 0.006\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "opt = optim.Adam(list(embed_data.parameters()) + list(embed_condition.parameters()), lr = 1e-3, betas = (0.9, 0.999))\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = 0.0\n",
    "for k in range(epoch):\n",
    "    for i, (data, condition) in enumerate(train_generator):\n",
    "        opt.zero_grad()\n",
    "        x = data.to(device)\n",
    "        y = condition.to(device)\n",
    "        output = embed_condition(embed_data(x))\n",
    "        loss = crit(output, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print('[%d] loss: %.3f' % (k + 1, running_loss / len(train_generator)))\n",
    "    running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embed_data.state_dict(), 'embed_data_weight.pt')\n",
    "torch.save(embed_condition.state_dict(), 'embed_condition_weight.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = nn.Sequential(\n",
    "    nn.Linear(49*2*d, d),\n",
    "    nn.BatchNorm1d(d),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.Linear(d, 10),\n",
    "    nn.Softmax(dim = 1),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec.load_state_dict(torch.load('embed_condition_weight.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0272, -0.0072,  0.0420,  ...,  0.0368,  0.0173,  0.0251],\n",
       "         [ 0.0459,  0.0209,  0.0736,  ...,  0.0055,  0.0183, -0.0106],\n",
       "         [ 0.0047,  0.0078,  0.0322,  ..., -0.0063,  0.0082,  0.0087],\n",
       "         ...,\n",
       "         [ 0.0373,  0.0126, -0.0186,  ...,  0.0112, -0.0154, -0.0446],\n",
       "         [ 0.0137, -0.0045, -0.0916,  ..., -0.0115, -0.0617, -0.0774],\n",
       "         [-0.0646,  0.0219, -0.0645,  ..., -0.0240, -0.0071, -0.0429]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1588, 0.1544, 0.1111, 0.1165, 0.1430, 0.1775, 0.1619, 0.0993, 0.1717,\n",
       "         0.1233, 0.1011, 0.1165, 0.1227, 0.2013, 0.1421, 0.1401, 0.1215, 0.0986,\n",
       "         0.1408, 0.1818, 0.1606, 0.1956, 0.1584, 0.1229, 0.1178, 0.1299, 0.1662,\n",
       "         0.1256, 0.1422, 0.1858, 0.1489, 0.1370, 0.1074, 0.1193, 0.1210, 0.1699,\n",
       "         0.1548, 0.1660, 0.1475, 0.1372, 0.1172, 0.1652, 0.1245, 0.1620, 0.1450,\n",
       "         0.0711, 0.1115, 0.1566, 0.1462, 0.0948, 0.1572, 0.1316, 0.1709, 0.1735,\n",
       "         0.1892, 0.1288, 0.1793, 0.0970, 0.1844, 0.1268, 0.1306, 0.1730, 0.1351,\n",
       "         0.1484], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.6122, 0.6393, 0.7050, 0.6355, 0.6538, 0.6647, 0.5986, 0.6032, 0.5832,\n",
       "         0.6954, 0.7219, 0.6115, 0.6302, 0.6545, 0.6150, 0.6508, 0.6357, 0.6588,\n",
       "         0.6960, 0.6673, 0.6590, 0.6263, 0.6099, 0.6089, 0.6614, 0.7479, 0.6702,\n",
       "         0.6734, 0.6899, 0.6985, 0.7142, 0.6784, 0.6646, 0.6558, 0.6783, 0.6196,\n",
       "         0.6659, 0.7443, 0.6748, 0.6512, 0.6070, 0.6028, 0.6603, 0.7319, 0.6241,\n",
       "         0.7256, 0.7099, 0.6791, 0.6659, 0.6718, 0.6075, 0.7231, 0.6383, 0.6579,\n",
       "         0.6504, 0.6668, 0.5888, 0.6425, 0.6553, 0.6546, 0.6683, 0.7281, 0.6744,\n",
       "         0.6329], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4062, 0.5090, 0.4827, 0.4923, 0.4330, 0.4496, 0.4263, 0.4714, 0.4299,\n",
       "         0.5035, 0.4938, 0.3717, 0.4372, 0.4248, 0.4193, 0.4882, 0.4612, 0.4602,\n",
       "         0.4857, 0.3570, 0.4268, 0.4171, 0.4335, 0.4127, 0.4296, 0.5269, 0.4535,\n",
       "         0.5342, 0.5200, 0.4269, 0.5460, 0.3644, 0.5135, 0.4128, 0.5233, 0.4516,\n",
       "         0.5543, 0.4827, 0.5040, 0.4930, 0.3881, 0.4678, 0.4062, 0.5614, 0.4970,\n",
       "         0.5563, 0.4086, 0.5222, 0.5094, 0.4281, 0.4894, 0.4527, 0.4555, 0.4732,\n",
       "         0.4965, 0.4457, 0.4392, 0.4994, 0.3860, 0.4941, 0.4840, 0.4808, 0.5018,\n",
       "         0.4926], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2857, -0.3530,  0.2545, -0.3277, -0.3710, -0.3522,  0.3379, -0.2421,\n",
       "          -0.2376,  0.3633, -0.3051, -0.2058,  0.2650,  0.2834, -0.3744, -0.2735,\n",
       "           0.2937,  0.3415,  0.3908, -0.3159,  0.2609, -0.3361,  0.2962, -0.2876,\n",
       "          -0.3691, -0.2854, -0.3134, -0.2999,  0.3107, -0.2994, -0.3337, -0.3160,\n",
       "          -0.1387, -0.3137,  0.2574,  0.3312,  0.3564, -0.3326, -0.2558, -0.2024,\n",
       "          -0.3183, -0.3405, -0.2027,  0.3091, -0.3136,  0.3219, -0.3168, -0.3487,\n",
       "          -0.3467,  0.3479, -0.2824, -0.2051,  0.2842, -0.3360, -0.3694, -0.3260,\n",
       "           0.3149, -0.3295, -0.2503, -0.2942, -0.3397,  0.2575,  0.3009,  0.3337],\n",
       "         [-0.3690, -0.3732, -0.3633, -0.3453,  0.3063, -0.3255,  0.1752,  0.2077,\n",
       "          -0.3505, -0.3602, -0.3387,  0.1769,  0.3152, -0.3366,  0.2864,  0.3116,\n",
       "           0.1137,  0.1871,  0.1601,  0.2447, -0.3411,  0.1998, -0.3610,  0.2280,\n",
       "           0.2602, -0.3706, -0.3225,  0.2034, -0.3775,  0.0916, -0.3687,  0.2570,\n",
       "          -0.3969,  0.2109,  0.2011,  0.2714,  0.2336,  0.1745, -0.3715,  0.2631,\n",
       "           0.2510,  0.0574,  0.2198, -0.3951, -0.3483, -0.3203, -0.3652, -0.1233,\n",
       "          -0.3470,  0.2543, -0.4037,  0.2426, -0.3208,  0.1933,  0.3094,  0.1457,\n",
       "          -0.4197, -0.3964,  0.2500,  0.1472, -0.3707, -0.2875, -0.3585,  0.2224],\n",
       "         [-0.3690, -0.2890,  0.3207, -0.3067,  0.2821, -0.3357, -0.3873, -0.2888,\n",
       "          -0.2206, -0.3118,  0.4113, -0.3558, -0.3785,  0.3216, -0.3586, -0.2456,\n",
       "           0.3055,  0.3217, -0.3958, -0.3487,  0.3095,  0.2921, -0.3490,  0.3640,\n",
       "          -0.3741,  0.2649,  0.2861, -0.2968, -0.3893, -0.3954, -0.3535, -0.3632,\n",
       "          -0.3124,  0.3482, -0.2983, -0.3357, -0.2940, -0.3214, -0.2563, -0.2729,\n",
       "           0.3877,  0.2770, -0.2872,  0.1978, -0.2960, -0.2445,  0.2640,  0.3233,\n",
       "          -0.3225, -0.3434,  0.3674, -0.2986,  0.3172,  0.3069, -0.3353, -0.3544,\n",
       "          -0.4339, -0.3753, -0.2768,  0.2880,  0.2992, -0.3144,  0.2968,  0.3592],\n",
       "         [ 0.2701, -0.3916, -0.1403, -0.3787,  0.3095,  0.2969,  0.2510, -0.3210,\n",
       "          -0.3322, -0.3209, -0.4015, -0.3585,  0.2450,  0.0603,  0.2665, -0.3413,\n",
       "          -0.1882, -0.3756, -0.3725,  0.4232,  0.1874,  0.3235,  0.1897, -0.3840,\n",
       "           0.2102,  0.2886,  0.3318, -0.3531,  0.3362,  0.3890,  0.2208,  0.3904,\n",
       "          -0.3148, -0.4004, -0.3831, -0.0970, -0.3469, -0.3661, -0.2657, -0.2996,\n",
       "          -0.4015,  0.2514, -0.3360,  0.1440, -0.3755, -0.3312,  0.3740, -0.4004,\n",
       "           0.2281, -0.3460, -0.3910, -0.2967,  0.0637,  0.1967,  0.2532, -0.3795,\n",
       "           0.1785,  0.3282, -0.3412,  0.0317, -0.3249,  0.1706,  0.0935, -0.4129],\n",
       "         [-0.2962,  0.3203, -0.2687,  0.1160, -0.3335,  0.3260, -0.3009,  0.1691,\n",
       "           0.3296,  0.2542,  0.2279, -0.2986, -0.2948, -0.2609, -0.3310,  0.2068,\n",
       "          -0.2957, -0.2856, -0.3388, -0.2730, -0.2750, -0.2938, -0.2535, -0.3252,\n",
       "          -0.2936,  0.3860, -0.1256,  0.2328, -0.1934, -0.3015, -0.4536, -0.2534,\n",
       "           0.2664, -0.2617,  0.5195, -0.2912,  0.3064,  0.4310,  0.2949,  0.2493,\n",
       "          -0.3395, -0.3219, -0.3280,  0.4843,  0.1872, -0.4454, -0.2838, -0.3189,\n",
       "          -0.4688, -0.3188,  0.2596,  0.4331, -0.2145, -0.2994,  0.2688, -0.3226,\n",
       "          -0.1913, -0.4770, -0.3369,  0.5047, -0.3117, -0.4726, -0.4886, -0.2840],\n",
       "         [ 0.2159,  0.3314,  0.2368,  0.3786, -0.3502,  0.2729, -0.3921, -0.2835,\n",
       "          -0.3743, -0.3602, -0.3445, -0.1917,  0.2414,  0.2999,  0.3195, -0.3123,\n",
       "           0.2809, -0.3577, -0.3241, -0.3676,  0.2862, -0.3638,  0.2465, -0.2413,\n",
       "           0.3219, -0.3360, -0.3617, -0.3438, -0.3851, -0.3105,  0.2630, -0.3554,\n",
       "          -0.2955, -0.2772,  0.2872,  0.1832, -0.3588,  0.3464, -0.3443, -0.2544,\n",
       "          -0.2454, -0.3740, -0.2826, -0.3808,  0.3804, -0.3543, -0.2270,  0.3536,\n",
       "           0.1714, -0.3412, -0.3316, -0.1987,  0.2876, -0.3319,  0.2954,  0.3784,\n",
       "           0.2385, -0.2364, -0.2456, -0.3372,  0.3524,  0.2177, -0.3695, -0.3517],\n",
       "         [-0.2670, -0.3457, -0.2833,  0.2617, -0.3331, -0.3471, -0.3128,  0.0628,\n",
       "          -0.2037,  0.3075, -0.3602,  0.2988, -0.2831, -0.2643, -0.2951, -0.3657,\n",
       "          -0.3289, -0.3421,  0.2690, -0.2946, -0.2912, -0.3237, -0.2334,  0.2803,\n",
       "          -0.3005,  0.2770, -0.2728, -0.3723,  0.3259,  0.3146,  0.2906, -0.2987,\n",
       "           0.2280, -0.3562, -0.3245, -0.2973, -0.3529, -0.3287, -0.3385,  0.1777,\n",
       "           0.2706, -0.3233,  0.2825, -0.3166,  0.2846,  0.2646,  0.3633,  0.2454,\n",
       "          -0.3240,  0.3146,  0.1312,  0.2347, -0.2575, -0.3087, -0.3844,  0.2782,\n",
       "          -0.1678,  0.2568,  0.3534,  0.2064,  0.3210, -0.3089, -0.3700, -0.3438],\n",
       "         [ 0.3536,  0.2412, -0.2930,  0.2252, -0.3127, -0.3956, -0.3115, -0.3571,\n",
       "           0.3317, -0.3662,  0.2844, -0.2580, -0.1553, -0.3440, -0.3498,  0.2101,\n",
       "          -0.3303, -0.2755, -0.2964,  0.3050, -0.3558, -0.2858,  0.3204, -0.2849,\n",
       "          -0.3266, -0.3276,  0.3187,  0.2384,  0.0751, -0.3102, -0.3734,  0.2958,\n",
       "          -0.3178, -0.2129,  0.2019,  0.3248,  0.1271, -0.3135,  0.3269, -0.3724,\n",
       "          -0.3047,  0.3446,  0.3305, -0.2642,  0.1182,  0.1898, -0.3046,  0.3041,\n",
       "           0.1832, -0.3232, -0.3296, -0.3179, -0.3301,  0.3307, -0.3875, -0.3055,\n",
       "          -0.3255,  0.2458,  0.3102, -0.3219,  0.3176, -0.3972, -0.3698,  0.3175],\n",
       "         [-0.3230,  0.3587,  0.3466, -0.3364, -0.4049, -0.3527,  0.2942,  0.2605,\n",
       "          -0.3273, -0.3568, -0.3534,  0.3571, -0.3773, -0.3611,  0.0348, -0.3751,\n",
       "           0.2812,  0.3075,  0.3052, -0.3504, -0.3745,  0.2989, -0.3035, -0.0547,\n",
       "           0.2669, -0.3612, -0.2945,  0.1974, -0.2957,  0.2873,  0.2664, -0.3380,\n",
       "           0.3545,  0.3053, -0.3305, -0.2700, -0.3616,  0.2501,  0.3775, -0.4007,\n",
       "          -0.1571,  0.3055, -0.3387,  0.2783, -0.3380, -0.2961, -0.3145, -0.3237,\n",
       "           0.2852, -0.3980,  0.3299, -0.3556, -0.3515, -0.2509, -0.4016,  0.3076,\n",
       "           0.3708,  0.3132, -0.3448, -0.3922, -0.3084, -0.3522,  0.2014, -0.3589],\n",
       "         [-0.3515,  0.0880, -0.2983,  0.2817,  0.0676,  0.3188, -0.1502,  0.3852,\n",
       "           0.2264,  0.2935,  0.2717, -0.3557, -0.2377, -0.2259, -0.1208,  0.3154,\n",
       "          -0.2843, -0.2193, -0.3348, -0.3301, -0.2085, -0.2347, -0.3698, -0.2787,\n",
       "          -0.2761, -0.1824, -0.3597,  0.2749, -0.3602, -0.3342,  0.3586, -0.3418,\n",
       "           0.2111, -0.2183, -0.4880, -0.3125,  0.2347, -0.5045,  0.1935,  0.3570,\n",
       "          -0.2867, -0.3447, -0.3575, -0.5084,  0.2465,  0.4252, -0.2899, -0.3320,\n",
       "           0.4165, -0.2293,  0.2461, -0.4762, -0.2219, -0.3022,  0.3481, -0.3501,\n",
       "          -0.3781,  0.3813, -0.3478, -0.5134, -0.3762,  0.4756,  0.4843, -0.2453]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2474, 0.0395, 0.2120, 0.0537, 0.2053, 0.1244, 0.1843, 0.1916, 0.1000,\n",
       "         0.1978], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in embed_condition.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0272, -0.0072,  0.0420,  ...,  0.0368,  0.0173,  0.0251],\n",
       "         [ 0.0459,  0.0209,  0.0736,  ...,  0.0055,  0.0183, -0.0106],\n",
       "         [ 0.0047,  0.0078,  0.0322,  ..., -0.0063,  0.0082,  0.0087],\n",
       "         ...,\n",
       "         [ 0.0373,  0.0126, -0.0186,  ...,  0.0112, -0.0154, -0.0446],\n",
       "         [ 0.0137, -0.0045, -0.0916,  ..., -0.0115, -0.0617, -0.0774],\n",
       "         [-0.0646,  0.0219, -0.0645,  ..., -0.0240, -0.0071, -0.0429]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1588, 0.1544, 0.1111, 0.1165, 0.1430, 0.1775, 0.1619, 0.0993, 0.1717,\n",
       "         0.1233, 0.1011, 0.1165, 0.1227, 0.2013, 0.1421, 0.1401, 0.1215, 0.0986,\n",
       "         0.1408, 0.1818, 0.1606, 0.1956, 0.1584, 0.1229, 0.1178, 0.1299, 0.1662,\n",
       "         0.1256, 0.1422, 0.1858, 0.1489, 0.1370, 0.1074, 0.1193, 0.1210, 0.1699,\n",
       "         0.1548, 0.1660, 0.1475, 0.1372, 0.1172, 0.1652, 0.1245, 0.1620, 0.1450,\n",
       "         0.0711, 0.1115, 0.1566, 0.1462, 0.0948, 0.1572, 0.1316, 0.1709, 0.1735,\n",
       "         0.1892, 0.1288, 0.1793, 0.0970, 0.1844, 0.1268, 0.1306, 0.1730, 0.1351,\n",
       "         0.1484], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.6122, 0.6393, 0.7050, 0.6355, 0.6538, 0.6647, 0.5986, 0.6032, 0.5832,\n",
       "         0.6954, 0.7219, 0.6115, 0.6302, 0.6545, 0.6150, 0.6508, 0.6357, 0.6588,\n",
       "         0.6960, 0.6673, 0.6590, 0.6263, 0.6099, 0.6089, 0.6614, 0.7479, 0.6702,\n",
       "         0.6734, 0.6899, 0.6985, 0.7142, 0.6784, 0.6646, 0.6558, 0.6783, 0.6196,\n",
       "         0.6659, 0.7443, 0.6748, 0.6512, 0.6070, 0.6028, 0.6603, 0.7319, 0.6241,\n",
       "         0.7256, 0.7099, 0.6791, 0.6659, 0.6718, 0.6075, 0.7231, 0.6383, 0.6579,\n",
       "         0.6504, 0.6668, 0.5888, 0.6425, 0.6553, 0.6546, 0.6683, 0.7281, 0.6744,\n",
       "         0.6329], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.4062, 0.5090, 0.4827, 0.4923, 0.4330, 0.4496, 0.4263, 0.4714, 0.4299,\n",
       "         0.5035, 0.4938, 0.3717, 0.4372, 0.4248, 0.4193, 0.4882, 0.4612, 0.4602,\n",
       "         0.4857, 0.3570, 0.4268, 0.4171, 0.4335, 0.4127, 0.4296, 0.5269, 0.4535,\n",
       "         0.5342, 0.5200, 0.4269, 0.5460, 0.3644, 0.5135, 0.4128, 0.5233, 0.4516,\n",
       "         0.5543, 0.4827, 0.5040, 0.4930, 0.3881, 0.4678, 0.4062, 0.5614, 0.4970,\n",
       "         0.5563, 0.4086, 0.5222, 0.5094, 0.4281, 0.4894, 0.4527, 0.4555, 0.4732,\n",
       "         0.4965, 0.4457, 0.4392, 0.4994, 0.3860, 0.4941, 0.4840, 0.4808, 0.5018,\n",
       "         0.4926], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2857, -0.3530,  0.2545, -0.3277, -0.3710, -0.3522,  0.3379, -0.2421,\n",
       "          -0.2376,  0.3633, -0.3051, -0.2058,  0.2650,  0.2834, -0.3744, -0.2735,\n",
       "           0.2937,  0.3415,  0.3908, -0.3159,  0.2609, -0.3361,  0.2962, -0.2876,\n",
       "          -0.3691, -0.2854, -0.3134, -0.2999,  0.3107, -0.2994, -0.3337, -0.3160,\n",
       "          -0.1387, -0.3137,  0.2574,  0.3312,  0.3564, -0.3326, -0.2558, -0.2024,\n",
       "          -0.3183, -0.3405, -0.2027,  0.3091, -0.3136,  0.3219, -0.3168, -0.3487,\n",
       "          -0.3467,  0.3479, -0.2824, -0.2051,  0.2842, -0.3360, -0.3694, -0.3260,\n",
       "           0.3149, -0.3295, -0.2503, -0.2942, -0.3397,  0.2575,  0.3009,  0.3337],\n",
       "         [-0.3690, -0.3732, -0.3633, -0.3453,  0.3063, -0.3255,  0.1752,  0.2077,\n",
       "          -0.3505, -0.3602, -0.3387,  0.1769,  0.3152, -0.3366,  0.2864,  0.3116,\n",
       "           0.1137,  0.1871,  0.1601,  0.2447, -0.3411,  0.1998, -0.3610,  0.2280,\n",
       "           0.2602, -0.3706, -0.3225,  0.2034, -0.3775,  0.0916, -0.3687,  0.2570,\n",
       "          -0.3969,  0.2109,  0.2011,  0.2714,  0.2336,  0.1745, -0.3715,  0.2631,\n",
       "           0.2510,  0.0574,  0.2198, -0.3951, -0.3483, -0.3203, -0.3652, -0.1233,\n",
       "          -0.3470,  0.2543, -0.4037,  0.2426, -0.3208,  0.1933,  0.3094,  0.1457,\n",
       "          -0.4197, -0.3964,  0.2500,  0.1472, -0.3707, -0.2875, -0.3585,  0.2224],\n",
       "         [-0.3690, -0.2890,  0.3207, -0.3067,  0.2821, -0.3357, -0.3873, -0.2888,\n",
       "          -0.2206, -0.3118,  0.4113, -0.3558, -0.3785,  0.3216, -0.3586, -0.2456,\n",
       "           0.3055,  0.3217, -0.3958, -0.3487,  0.3095,  0.2921, -0.3490,  0.3640,\n",
       "          -0.3741,  0.2649,  0.2861, -0.2968, -0.3893, -0.3954, -0.3535, -0.3632,\n",
       "          -0.3124,  0.3482, -0.2983, -0.3357, -0.2940, -0.3214, -0.2563, -0.2729,\n",
       "           0.3877,  0.2770, -0.2872,  0.1978, -0.2960, -0.2445,  0.2640,  0.3233,\n",
       "          -0.3225, -0.3434,  0.3674, -0.2986,  0.3172,  0.3069, -0.3353, -0.3544,\n",
       "          -0.4339, -0.3753, -0.2768,  0.2880,  0.2992, -0.3144,  0.2968,  0.3592],\n",
       "         [ 0.2701, -0.3916, -0.1403, -0.3787,  0.3095,  0.2969,  0.2510, -0.3210,\n",
       "          -0.3322, -0.3209, -0.4015, -0.3585,  0.2450,  0.0603,  0.2665, -0.3413,\n",
       "          -0.1882, -0.3756, -0.3725,  0.4232,  0.1874,  0.3235,  0.1897, -0.3840,\n",
       "           0.2102,  0.2886,  0.3318, -0.3531,  0.3362,  0.3890,  0.2208,  0.3904,\n",
       "          -0.3148, -0.4004, -0.3831, -0.0970, -0.3469, -0.3661, -0.2657, -0.2996,\n",
       "          -0.4015,  0.2514, -0.3360,  0.1440, -0.3755, -0.3312,  0.3740, -0.4004,\n",
       "           0.2281, -0.3460, -0.3910, -0.2967,  0.0637,  0.1967,  0.2532, -0.3795,\n",
       "           0.1785,  0.3282, -0.3412,  0.0317, -0.3249,  0.1706,  0.0935, -0.4129],\n",
       "         [-0.2962,  0.3203, -0.2687,  0.1160, -0.3335,  0.3260, -0.3009,  0.1691,\n",
       "           0.3296,  0.2542,  0.2279, -0.2986, -0.2948, -0.2609, -0.3310,  0.2068,\n",
       "          -0.2957, -0.2856, -0.3388, -0.2730, -0.2750, -0.2938, -0.2535, -0.3252,\n",
       "          -0.2936,  0.3860, -0.1256,  0.2328, -0.1934, -0.3015, -0.4536, -0.2534,\n",
       "           0.2664, -0.2617,  0.5195, -0.2912,  0.3064,  0.4310,  0.2949,  0.2493,\n",
       "          -0.3395, -0.3219, -0.3280,  0.4843,  0.1872, -0.4454, -0.2838, -0.3189,\n",
       "          -0.4688, -0.3188,  0.2596,  0.4331, -0.2145, -0.2994,  0.2688, -0.3226,\n",
       "          -0.1913, -0.4770, -0.3369,  0.5047, -0.3117, -0.4726, -0.4886, -0.2840],\n",
       "         [ 0.2159,  0.3314,  0.2368,  0.3786, -0.3502,  0.2729, -0.3921, -0.2835,\n",
       "          -0.3743, -0.3602, -0.3445, -0.1917,  0.2414,  0.2999,  0.3195, -0.3123,\n",
       "           0.2809, -0.3577, -0.3241, -0.3676,  0.2862, -0.3638,  0.2465, -0.2413,\n",
       "           0.3219, -0.3360, -0.3617, -0.3438, -0.3851, -0.3105,  0.2630, -0.3554,\n",
       "          -0.2955, -0.2772,  0.2872,  0.1832, -0.3588,  0.3464, -0.3443, -0.2544,\n",
       "          -0.2454, -0.3740, -0.2826, -0.3808,  0.3804, -0.3543, -0.2270,  0.3536,\n",
       "           0.1714, -0.3412, -0.3316, -0.1987,  0.2876, -0.3319,  0.2954,  0.3784,\n",
       "           0.2385, -0.2364, -0.2456, -0.3372,  0.3524,  0.2177, -0.3695, -0.3517],\n",
       "         [-0.2670, -0.3457, -0.2833,  0.2617, -0.3331, -0.3471, -0.3128,  0.0628,\n",
       "          -0.2037,  0.3075, -0.3602,  0.2988, -0.2831, -0.2643, -0.2951, -0.3657,\n",
       "          -0.3289, -0.3421,  0.2690, -0.2946, -0.2912, -0.3237, -0.2334,  0.2803,\n",
       "          -0.3005,  0.2770, -0.2728, -0.3723,  0.3259,  0.3146,  0.2906, -0.2987,\n",
       "           0.2280, -0.3562, -0.3245, -0.2973, -0.3529, -0.3287, -0.3385,  0.1777,\n",
       "           0.2706, -0.3233,  0.2825, -0.3166,  0.2846,  0.2646,  0.3633,  0.2454,\n",
       "          -0.3240,  0.3146,  0.1312,  0.2347, -0.2575, -0.3087, -0.3844,  0.2782,\n",
       "          -0.1678,  0.2568,  0.3534,  0.2064,  0.3210, -0.3089, -0.3700, -0.3438],\n",
       "         [ 0.3536,  0.2412, -0.2930,  0.2252, -0.3127, -0.3956, -0.3115, -0.3571,\n",
       "           0.3317, -0.3662,  0.2844, -0.2580, -0.1553, -0.3440, -0.3498,  0.2101,\n",
       "          -0.3303, -0.2755, -0.2964,  0.3050, -0.3558, -0.2858,  0.3204, -0.2849,\n",
       "          -0.3266, -0.3276,  0.3187,  0.2384,  0.0751, -0.3102, -0.3734,  0.2958,\n",
       "          -0.3178, -0.2129,  0.2019,  0.3248,  0.1271, -0.3135,  0.3269, -0.3724,\n",
       "          -0.3047,  0.3446,  0.3305, -0.2642,  0.1182,  0.1898, -0.3046,  0.3041,\n",
       "           0.1832, -0.3232, -0.3296, -0.3179, -0.3301,  0.3307, -0.3875, -0.3055,\n",
       "          -0.3255,  0.2458,  0.3102, -0.3219,  0.3176, -0.3972, -0.3698,  0.3175],\n",
       "         [-0.3230,  0.3587,  0.3466, -0.3364, -0.4049, -0.3527,  0.2942,  0.2605,\n",
       "          -0.3273, -0.3568, -0.3534,  0.3571, -0.3773, -0.3611,  0.0348, -0.3751,\n",
       "           0.2812,  0.3075,  0.3052, -0.3504, -0.3745,  0.2989, -0.3035, -0.0547,\n",
       "           0.2669, -0.3612, -0.2945,  0.1974, -0.2957,  0.2873,  0.2664, -0.3380,\n",
       "           0.3545,  0.3053, -0.3305, -0.2700, -0.3616,  0.2501,  0.3775, -0.4007,\n",
       "          -0.1571,  0.3055, -0.3387,  0.2783, -0.3380, -0.2961, -0.3145, -0.3237,\n",
       "           0.2852, -0.3980,  0.3299, -0.3556, -0.3515, -0.2509, -0.4016,  0.3076,\n",
       "           0.3708,  0.3132, -0.3448, -0.3922, -0.3084, -0.3522,  0.2014, -0.3589],\n",
       "         [-0.3515,  0.0880, -0.2983,  0.2817,  0.0676,  0.3188, -0.1502,  0.3852,\n",
       "           0.2264,  0.2935,  0.2717, -0.3557, -0.2377, -0.2259, -0.1208,  0.3154,\n",
       "          -0.2843, -0.2193, -0.3348, -0.3301, -0.2085, -0.2347, -0.3698, -0.2787,\n",
       "          -0.2761, -0.1824, -0.3597,  0.2749, -0.3602, -0.3342,  0.3586, -0.3418,\n",
       "           0.2111, -0.2183, -0.4880, -0.3125,  0.2347, -0.5045,  0.1935,  0.3570,\n",
       "          -0.2867, -0.3447, -0.3575, -0.5084,  0.2465,  0.4252, -0.2899, -0.3320,\n",
       "           0.4165, -0.2293,  0.2461, -0.4762, -0.2219, -0.3022,  0.3481, -0.3501,\n",
       "          -0.3781,  0.3813, -0.3478, -0.5134, -0.3762,  0.4756,  0.4843, -0.2453]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2474, 0.0395, 0.2120, 0.0537, 0.2053, 0.1244, 0.1843, 0.1916, 0.1000,\n",
       "         0.1978], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in ec.parameters()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
